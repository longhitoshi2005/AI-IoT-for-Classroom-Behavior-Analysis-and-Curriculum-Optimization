# ğŸ“ Edubot Backend (AIoT Classroom Assistant)

Edubot lÃ  chatbot há»— trá»£ giÃ¡o viÃªn phÃ¢n tÃ­ch hÃ nh vi lá»›p há»c vÃ  gá»£i Ã½ cáº£i thiá»‡n bÃ i giáº£ng, slide, ká»¹ nÄƒng giáº£ng dáº¡y.  
Tráº£ lá»i **báº±ng tiáº¿ng Viá»‡t**, dá»±a vÃ o RAG (FAISS + dá»¯ liá»‡u scrape UNESCO, Edutopia, Tes, Khan Academy, ISTE, â€¦) vÃ  sá»‘ liá»‡u thá»±c táº¿ tá»« lá»›p há»c.

---

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u
- Python >= 3.10
- [Ollama](https://ollama.com/download) (Ä‘á»ƒ cháº¡y model ngÃ´n ngá»¯)
- ÄÃ£ pull model Ollama:
  ```bash
  ollama pull phi3:mini
  ```

### Clone & cÃ i thÆ° viá»‡n

```bash
git clone <link-repo>
cd chatbot-edubot
python -m venv .venv
# Linux/Mac:
source .venv/bin/activate
# Windows PowerShell:
.venv\Scripts\Activate.ps1

pip install -r requirements.txt
```

### Cáº¥u hÃ¬nh

Táº¡o file `.env` tá»« máº«u:

```env
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=phi3:mini

# Embedding
EMBEDDING_MODEL=all-MiniLM-L6-v2
FAISS_INDEX_PATH=data/education.index
CHUNKS_PATH=data/education_chunks.pkl
```

### Khá»Ÿi Ä‘á»™ng server

```bash
uvicorn server:app --host 0.0.0.0 --port 5000
```

Server cháº¡y táº¡i: [http://localhost:5000](http://localhost:5000)

---

## ğŸ”Œ API Endpoints

### `GET /health`
Kiá»ƒm tra tráº¡ng thÃ¡i:
```json
{"ok": true, "ollama": true}
```

### `POST /chat`
Input máº«u:
```json
{
  "query": "Gá»£i Ã½ cáº£i thiá»‡n má»©c Ä‘á»™ táº­p trung trong 15 phÃºt Ä‘áº§u tiáº¿t há»c?",
  "k": 4,
  "csv_paths": ["data/detections_20250913_224734.csv"],
  "json_paths": ["data/enhanced_session_stats_20250913_224734.json"]
}
```
Output máº«u:
```json
{"response": "â€¦tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, gá»“m tÃ³m táº¯t, káº¿ hoáº¡ch hÃ nh Ä‘á»™ng, checklistâ€¦"}
```

### `POST /ingest`
Tuá»³ chá»n: rebuild FAISS index tá»« `education_content.txt`.

---

## ğŸ³ Cháº¡y báº±ng Docker

```bash
docker build -t edubot-backend .
docker run -d -p 5000:5000 --env-file .env edubot-backend
```

---

## âœ… LÆ°u Ã½ báº£o máº­t & dá»¯ liá»‡u

- Äáº£m báº£o Ollama luÃ´n cháº¡y (`ollama serve`).
- Dá»¯ liá»‡u CSV/JSON lá»›p há»c pháº£i **áº©n danh**, tuÃ¢n thá»§ báº£o máº­t.
- Náº¿u deploy public: thÃªm HTTPS, giá»›i háº¡n truy cáº­p, log & giÃ¡m sÃ¡t.

---

ğŸš€ CÃ¡ch 1 â€” Cháº¡y trá»±c tiáº¿p báº±ng Python (dá»… nháº¥t)
BÆ°á»›c 1. CÃ i Ollama

Táº£i Ollama
 â†’ cÃ i Ä‘áº·t â†’ má»Ÿ terminal cháº¡y:

ollama pull phi3:mini
ollama serve


Kiá»ƒm tra:

curl http://localhost:11434/api/tags


â†’ pháº£i tháº¥y "phi3:mini".

BÆ°á»›c 2. Chuáº©n bá»‹ backend

Copy toÃ n bá»™ project chatbot-edubot (cÃ¡c file server.py, ai_client.py, rag.py, â€¦ vÃ  thÆ° má»¥c data/) vÃ o mÃ¡y tÃ­nh cÃ¡ nhÃ¢n.

Táº¡o mÃ´i trÆ°á»ng áº£o:

python -m venv .venv
# Windows PowerShell:
.venv\Scripts\Activate.ps1
# Linux/Mac:
source .venv/bin/activate


CÃ i thÆ° viá»‡n:

pip install -r requirements.txt

BÆ°á»›c 3. Cáº¥u hÃ¬nh .env

Táº¡o file .env trong thÆ° má»¥c gá»‘c:

OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=phi3:mini
EMBEDDING_MODEL=all-MiniLM-L6-v2
FAISS_INDEX_PATH=data/education.index
CHUNKS_PATH=data/education_chunks.pkl

BÆ°á»›c 4. Cháº¡y server
uvicorn server:app --host 0.0.0.0 --port 5000


â†’ Backend cháº¡y táº¡i http://localhost:5000.

BÆ°á»›c 5. Test

Má»Ÿ Postman, Insomnia hoáº·c trÃ¬nh duyá»‡t + fetch API:

curl -X POST http://localhost:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"query":"Gá»£i Ã½ cáº£i thiá»‡n má»©c Ä‘á»™ táº­p trung trong 15 phÃºt Ä‘áº§u tiáº¿t há»c?"}'

ğŸ³ CÃ¡ch 2 â€” Cháº¡y báº±ng Docker (tiá»‡n deploy)
BÆ°á»›c 1. Build image

Trong thÆ° má»¥c project:

docker build -t edubot-backend .

BÆ°á»›c 2. Cháº¡y container
docker run -d -p 5000:5000 --env-file .env edubot-backend

BÆ°á»›c 3. Kiá»ƒm tra

Má»Ÿ http://localhost:5000/health
 â†’ tháº¥y:

{"ok": true, "ollama": true}

ğŸŒ TÃ­ch há»£p vá»›i UI

Náº¿u frontend náº±m chung mÃ¡y: chá»‰ cáº§n gá»i API:

fetch("http://localhost:5000/chat", {
  method: "POST",
  headers: {"Content-Type": "application/json"},
  body: JSON.stringify({ query: "Gá»£i Ã½ tÄƒng tÆ°Æ¡ng tÃ¡c há»c sinh" })
}).then(r => r.json()).then(console.log)


Náº¿u muá»‘n cháº¡y trÃªn domain/webserver: thÃªm Nginx proxy Ä‘á»ƒ trá» /api â†’ backend.

ğŸ‘‰ TÃ³m láº¡i:

MÃ¡y cÃ¡ nhÃ¢n: cÃ i Ollama + Python, cháº¡y uvicorn server:app.
Test: gá»i http://localhost:5000/chat tá»« UI hoáº·c curl.
Triá»ƒn khai: náº¿u muá»‘n gá»n gÃ ng â†’ dÃ¹ng Docker